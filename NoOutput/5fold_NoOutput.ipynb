{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartaCampagnoli/MLCatsandDogs/blob/main/NoOutput/5fold_NoOutput.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3uvUJAZPg2q"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from os import listdir\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import pathlib\n",
        "from skimage.io import imread\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import models, layers, callbacks, regularizers\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical, load_img, img_to_array\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import  SGD, RMSprop, Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score, zero_one_loss, confusion_matrix\n",
        "\n",
        "!pip install visualkeras\n",
        "import visualkeras\n",
        "!pip install wget\n",
        "import wget \n",
        "import zipfile\n",
        "\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXnDmXR7RDr2"
      },
      "outputs": [],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(\"cats_vs_dogs.zip\"): #downloading the dataset\n",
        "    print(\"downloading...\")\n",
        "    wget.download(\"https://unimibox.unimi.it/index.php/s/eNGYGSYmqynNMqF/download\")\n"
      ],
      "metadata": {
        "id": "QIeOUCqxaq7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not (os.path.isdir(\"data\") and os.path.isdir(\"data/Cats\") and os.path.isdir(\"data/Dogs\")): #unzipping\n",
        "    print(\"extracting...\")\n",
        "    with zipfile.ZipFile(\"CatsDogs.zip\", 'r') as file: file.extractall(\"./data/\")"
      ],
      "metadata": {
        "id": "NdVgViLMbhte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoYf0qrSXwGP"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/data/CatsDogs\"\n",
        "cats_dir = data_dir + '/Cats'\n",
        "dogs_dir = data_dir + '/Dogs'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQKRCEGSqhhQ"
      },
      "outputs": [],
      "source": [
        "size = (100, 100)\n",
        "channels = 1\n",
        "catsdogs = []\n",
        "categories = ['Cats','Dogs']\n",
        "\n",
        "def get_data():\n",
        "\n",
        "    for category in categories:\n",
        "        path = os.path.join(data_dir, category)\n",
        "\n",
        "        animalclass = categories.index(category)\n",
        "\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
        "                new_array = cv2.resize(img_array, size)\n",
        "                catsdogs.append([new_array, animalclass])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "get_data()\n",
        "\n",
        "print(len(catsdogs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi6N7zGMrglw"
      },
      "outputs": [],
      "source": [
        "random.shuffle(catsdogs)\n",
        "#for sample in catsdogs[:4]:\n",
        "    #print(sample[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1THknCtjFbQo"
      },
      "outputs": [],
      "source": [
        "X = [] #getting the images and labels, casting them to tensor\n",
        "y = []\n",
        "\n",
        "for image, label in catsdogs:\n",
        "    X.append(image)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, 100, 100, channels)\n",
        "size = X.shape[0]\n",
        "X = tf.convert_to_tensor(X, dtype= tf.float32) / 255.0\n",
        "Y = tf.reshape(tf.convert_to_tensor(y, dtype=tf.float32), shape = [size, 1])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training loss, optimizers\n",
        "                                         \n",
        "loss = keras.losses.BinaryCrossentropy()\n",
        "\n",
        "RMSProp = RMSprop(learning_rate=0.001)\n",
        "ADAM = Adam()"
      ],
      "metadata": {
        "id": "FY0aSG4FzfXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  true_label, img = true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.gray)\n",
        "\n",
        "  \n",
        "  if predictions_array == true_label:\n",
        "    color = 'forestgreen'\n",
        "  else:\n",
        "    color = 'darkmagenta'\n",
        "\n",
        "  plt.xlabel(\"{} ({})\".format(categories[predictions_array],\n",
        "                                categories[true_label]),\n",
        "                                color=color)\n"
      ],
      "metadata": {
        "id": "7Ktj806lOULk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***5-fold cross-validation on Drop256 (dropout and convolutional layers) using RMSPROP***"
      ],
      "metadata": {
        "id": "7mA0HlJweW-Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsrSth09Sjp5"
      },
      "outputs": [],
      "source": [
        "model_accuracy = []\n",
        "model_loss = []\n",
        "\n",
        "\n",
        "splits = 5\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "\n",
        "fold_num = 1\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
        "\n",
        "    drop256 = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "\n",
        "    drop256.compile(optimizer = RMSProp, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_num} ...')\n",
        "\n",
        "    history = drop256.fit(X_train, y_train, epochs = 50, batch_size = 64, verbose = 0)\n",
        "\n",
        "    #predicting and rounding to 0 and 1, computing the zero-one loss\n",
        "\n",
        "    y_predictions = drop256.predict(X_test)\n",
        "    y_predictions_np = tf.round(y_predictions).numpy()\n",
        "    y_test_np = y_test.numpy() #true test labels\n",
        "\n",
        "    model_accuracy.append(accuracy_score(y_test_np, y_predictions_np))\n",
        "    model_loss.append(zero_one_loss(y_test_np, y_predictions_np))\n",
        "\n",
        "#metrics for each fold\n",
        "    print(f'Score for fold {fold_num}: Loss of {zero_one_loss(y_test_np, y_predictions_np)}; Accuracy of {accuracy_score(y_test_np, y_predictions_np)}')\n",
        "\n",
        "    fold_num = fold_num + 1\n",
        "\n",
        "#average metrics\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(model_loss)):\n",
        "    print(f'> Fold {i + 1} - Loss: {model_loss[i]} - Accuracy: {model_accuracy[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(model_accuracy)} (+- {np.std(model_accuracy)})')\n",
        "print(f'> Zero-one Loss: {np.mean(model_loss)}')\n",
        "print('------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTF4q0cnYSME"
      },
      "outputs": [],
      "source": [
        "#computing the confusion matrix for predictions for Fold 5\n",
        "confusion_mtx = confusion_matrix(y_test_np, y_predictions_np) \n",
        "\n",
        "f,ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if y_predictions[0] > 0.5: #checking one prediction manually, just this one time\n",
        "    print(f'It\\'s a dog!')\n",
        "else:\n",
        "    print(f'It\\'s a cat!')\n"
      ],
      "metadata": {
        "id": "uPIHyDdgMBjo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predictions[0], y_predictions_np[0], y_test_np[0] #prediction and true label"
      ],
      "metadata": {
        "id": "lGyvypdKY0vo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10,10)) #corresponding image\n",
        "plt.subplot(5,5,i+1)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.grid(False)\n",
        "plt.imshow(X_test[0], cmap=plt.cm.gray)\n",
        "plt.title(y_test_np[0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QSzRO0h2Yw9R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adapting arrays to use in the plot_image function\n",
        "\n",
        "y_test_np = y_test_np.astype(int)\n",
        "y_predictions_np = y_predictions_np.astype(int)\n",
        "y_test_np1 = y_test_np.flatten()\n",
        "y_pred_np1 = y_predictions_np.flatten()\n",
        "\n",
        "out_images = np.array(X_test)"
      ],
      "metadata": {
        "id": "2JxIrtzaqoqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first 15 test images, their predicted labels, and the true labels.\n",
        "# correct predictions are in green and incorrect predictions in red.\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, y_pred_np1[i], y_test_np1, out_images)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Xq3EIuRJqsMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***5-fold cross-validation on Drop256 (dropout and convolutional layers) using ADAM***"
      ],
      "metadata": {
        "id": "1vUAWxKAsx_T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVOpheaYsx_m"
      },
      "outputs": [],
      "source": [
        "model_accuracy = []\n",
        "model_loss = []\n",
        "\n",
        "\n",
        "splits = 5\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "\n",
        "fold_num = 1\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
        "\n",
        "    drop256 = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "\n",
        "    drop256.compile(optimizer = ADAM, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_num} ...')\n",
        "\n",
        "    history = drop256.fit(X_train, y_train, epochs = 50, batch_size = 64, verbose = 0)\n",
        "\n",
        "    #predicting and rounding to 0 and 1, computing the zero-one loss\n",
        "\n",
        "    y_predictions = drop256.predict(X_test)\n",
        "    y_predictions_np = tf.round(y_predictions).numpy()\n",
        "    y_test_np = y_test.numpy() #true test labels\n",
        "\n",
        "    model_accuracy.append(accuracy_score(y_test_np, y_predictions_np))\n",
        "    model_loss.append(zero_one_loss(y_test_np, y_predictions_np))\n",
        "\n",
        "#metrics for each fold\n",
        "    print(f'Score for fold {fold_num}: Loss of {zero_one_loss(y_test_np, y_predictions_np)}; Accuracy of {accuracy_score(y_test_np, y_predictions_np)}')\n",
        "\n",
        "    fold_num = fold_num + 1\n",
        "\n",
        "#average metrics\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(model_loss)):\n",
        "    print(f'> Fold {i + 1} - Loss: {model_loss[i]} - Accuracy: {model_accuracy[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(model_accuracy)} (+- {np.std(model_accuracy)})')\n",
        "print(f'> Zero-one Loss: {np.mean(model_loss)}')\n",
        "print('------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Blsolucxsx_p"
      },
      "outputs": [],
      "source": [
        "#computing the confusion matrix for predictions for Fold 5\n",
        "confusion_mtx = confusion_matrix(y_test_np, y_predictions_np) \n",
        "\n",
        "f,ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adapting arrays to use in the plot_image function\n",
        "\n",
        "y_test_np = y_test_np.astype(int)\n",
        "y_predictions_np = y_predictions_np.astype(int)\n",
        "y_test_np1 = y_test_np.flatten()\n",
        "y_pred_np1 = y_predictions_np.flatten()\n",
        "\n",
        "out_images = np.array(X_test)"
      ],
      "metadata": {
        "id": "uOVYrNaHsx_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first 15 test images, their predicted labels, and the true labels.\n",
        "# correct predictions are in green and incorrect predictions in red.\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, y_pred_np1[i], y_test_np1, out_images)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lc9BBk-ksx_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***5-fold cross-validation on DropBatch256 (dropout, batch normalization and convolutional layers) using RMSPROP***"
      ],
      "metadata": {
        "id": "DV5YCPrzs5Tp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZlZIRCEs5Up"
      },
      "outputs": [],
      "source": [
        "model_accuracy = []\n",
        "model_loss = []\n",
        "\n",
        "\n",
        "splits = 5\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "\n",
        "fold_num = 1\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
        "\n",
        "    dropbatch256 = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "    dropbatch256.compile(optimizer = RMSProp, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_num} ...')\n",
        "\n",
        "    history = dropbatch256.fit(X_train, y_train, epochs = 50, batch_size = 64, verbose = 0)\n",
        "\n",
        "    #predicting and rounding to 0 and 1, computing the zero-one loss\n",
        "\n",
        "    y_predictions = dropbatch256.predict(X_test)\n",
        "    y_predictions_np = tf.round(y_predictions).numpy()\n",
        "    y_test_np = y_test.numpy() #true test labels\n",
        "\n",
        "    model_accuracy.append(accuracy_score(y_test_np, y_predictions_np))\n",
        "    model_loss.append(zero_one_loss(y_test_np, y_predictions_np))\n",
        "\n",
        "#metrics for each fold\n",
        "    print(f'Score for fold {fold_num}: Loss of {zero_one_loss(y_test_np, y_predictions_np)}; Accuracy of {accuracy_score(y_test_np, y_predictions_np)}')\n",
        "\n",
        "    fold_num = fold_num + 1\n",
        "\n",
        "#average metrics\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(model_loss)):\n",
        "    print(f'> Fold {i + 1} - Loss: {model_loss[i]} - Accuracy: {model_accuracy[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(model_accuracy)} (+- {np.std(model_accuracy)})')\n",
        "print(f'> Zero-one Loss: {np.mean(model_loss)}')\n",
        "print('------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H5inw4Zts5Ur"
      },
      "outputs": [],
      "source": [
        "# computing the confusion matrix for predictions for fold 5\n",
        "confusion_mtx = confusion_matrix(y_test_np, y_predictions_np) \n",
        "\n",
        "f,ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adapting arrays to use in the plot_image function\n",
        "\n",
        "y_test_np = y_test_np.astype(int)\n",
        "y_predictions_np = y_predictions_np.astype(int)\n",
        "y_test_np1 = y_test_np.flatten()\n",
        "y_pred_np1 = y_predictions_np.flatten()\n",
        "\n",
        "out_images = np.array(X_test)"
      ],
      "metadata": {
        "id": "cdfBYb9Rs5Ut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first 15 test images, their predicted labels, and the true labels.\n",
        "# correct predictions are in green and incorrect predictions in red.\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, y_pred_np1[i], y_test_np1, out_images)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "o6t-lRZNs5Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***5-fold cross-validation on DropBatch256 (dropout, batch normalization and convolutional layers) using ADAM***"
      ],
      "metadata": {
        "id": "gvz5ARjctEML"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yXFqhUJwtEMp"
      },
      "outputs": [],
      "source": [
        "model_accuracy = []\n",
        "model_loss = []\n",
        "\n",
        "\n",
        "splits = 5\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "\n",
        "fold_num = 1\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
        "\n",
        "    dropbatch256 = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "    dropbatch256.compile(optimizer = ADAM, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_num} ...')\n",
        "\n",
        "    history = dropbatch256.fit(X_train, y_train, epochs = 50, batch_size = 64, verbose = 0)\n",
        "\n",
        "    #predicting and rounding to 0 and 1, computing the zero-one loss\n",
        "\n",
        "    y_predictions = dropbatch256.predict(X_test)\n",
        "    y_predictions_np = tf.round(y_predictions).numpy()\n",
        "    y_test_np = y_test.numpy() #true test labels\n",
        "\n",
        "    model_accuracy.append(accuracy_score(y_test_np, y_predictions_np))\n",
        "    model_loss.append(zero_one_loss(y_test_np, y_predictions_np))\n",
        "\n",
        "#metrics for each fold\n",
        "    print(f'Score for fold {fold_num}: Loss of {zero_one_loss(y_test_np, y_predictions_np)}; Accuracy of {accuracy_score(y_test_np, y_predictions_np)}')\n",
        "\n",
        "    fold_num = fold_num + 1\n",
        "\n",
        "#average metrics\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(model_loss)):\n",
        "    print(f'> Fold {i + 1} - Loss: {model_loss[i]} - Accuracy: {model_accuracy[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(model_accuracy)} (+- {np.std(model_accuracy)})')\n",
        "print(f'> Zero-one Loss: {np.mean(model_loss)}')\n",
        "print('------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6gEMyB3tEMr"
      },
      "outputs": [],
      "source": [
        "# computing the confusion matrix for predictions for fold 5\n",
        "confusion_mtx = confusion_matrix(y_test_np, y_predictions_np) \n",
        "\n",
        "f,ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adapting arrays to use in the plot_image function\n",
        "\n",
        "y_test_np = y_test_np.astype(int)\n",
        "y_predictions_np = y_predictions_np.astype(int)\n",
        "y_test_np1 = y_test_np.flatten()\n",
        "y_pred_np1 = y_predictions_np.flatten()\n",
        "\n",
        "out_images = np.array(X_test)"
      ],
      "metadata": {
        "id": "XsVCseUgtEMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first 15 test images, their predicted labels, and the true labels.\n",
        "# correct predictions are in green and incorrect predictions in red.\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, y_pred_np1[i], y_test_np1, out_images)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "V7hlVKYMtEMt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***5-fold cross-validation on DropBatch512 (dropout, batch normalization and convolutional layers) using RMSPROP***"
      ],
      "metadata": {
        "id": "B29xE_DDt8Kc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wi57bHrlt8Ky"
      },
      "outputs": [],
      "source": [
        "model_accuracy = []\n",
        "model_loss = []\n",
        "\n",
        "\n",
        "splits = 5\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "\n",
        "fold_num = 1\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
        "\n",
        "    dropbatch512 = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.15),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.15),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "\n",
        "    dropbatch512.compile(optimizer = RMSProp, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_num} ...')\n",
        "\n",
        "    history = dropbatch512.fit(X_train, y_train, epochs = 50, batch_size = 64, verbose = 0)\n",
        "\n",
        "    #predicting and rounding to 0 and 1, computing the zero-one loss\n",
        "\n",
        "    y_predictions = dropbatch512.predict(X_test)\n",
        "    y_predictions_np = tf.round(y_predictions).numpy()\n",
        "    y_test_np = y_test.numpy() #true test labels\n",
        "\n",
        "    model_accuracy.append(accuracy_score(y_test_np, y_predictions_np))\n",
        "    model_loss.append(zero_one_loss(y_test_np, y_predictions_np))\n",
        "\n",
        "#metrics for each fold\n",
        "    print(f'Score for fold {fold_num}: Loss of {zero_one_loss(y_test_np, y_predictions_np)}; Accuracy of {accuracy_score(y_test_np, y_predictions_np)}')\n",
        "\n",
        "    fold_num = fold_num + 1\n",
        "\n",
        "#average metrics\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(model_loss)):\n",
        "    print(f'> Fold {i + 1} - Loss: {model_loss[i]} - Accuracy: {model_accuracy[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(model_accuracy)} (+- {np.std(model_accuracy)})')\n",
        "print(f'> Zero-one Loss: {np.mean(model_loss)}')\n",
        "print('------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4VUi3jct8Kz"
      },
      "outputs": [],
      "source": [
        "# computing the confusion matrix for predictions at Fold 5\n",
        "confusion_mtx = confusion_matrix(y_test_np, y_predictions_np) \n",
        "f,ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adapting arrays to use in the plot_image function\n",
        "\n",
        "y_test_np = y_test_np.astype(int)\n",
        "y_predictions_np = y_predictions_np.astype(int)\n",
        "y_test_np1 = y_test_np.flatten()\n",
        "y_pred_np1 = y_predictions_np.flatten()\n",
        "\n",
        "out_images = np.array(X_test)"
      ],
      "metadata": {
        "id": "qz5QgE6qt8K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first 15 test images, their predicted labels, and the true labels.\n",
        "# correct predictions are in green and incorrect predictions in red.\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, y_pred_np1[i], y_test_np1, out_images)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WJOKh0-dt8K1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***5-fold cross-validation on DropBatch512 (dropout, batch normalization and convolutional layers) using ADAM***"
      ],
      "metadata": {
        "id": "MHzxU_yFt8K1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UD5xruuut8K1"
      },
      "outputs": [],
      "source": [
        "model_accuracy = []\n",
        "model_loss = []\n",
        "\n",
        "\n",
        "splits = 5\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "\n",
        "fold_num = 1\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
        "\n",
        "    dropbatch512 = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.15),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.15),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.25),\n",
        "        tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "\n",
        "    dropbatch512.compile(optimizer = ADAM, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_num} ...')\n",
        "\n",
        "    history = dropbatch512.fit(X_train, y_train, epochs = 50, batch_size = 64, verbose = 0)\n",
        "\n",
        "    #predicting and rounding to 0 and 1, computing the zero-one loss\n",
        "\n",
        "    y_predictions = dropbatch512.predict(X_test)\n",
        "    y_predictions_np = tf.round(y_predictions).numpy()\n",
        "    y_test_np = y_test.numpy() #true test labels\n",
        "\n",
        "    model_accuracy.append(accuracy_score(y_test_np, y_predictions_np))\n",
        "    model_loss.append(zero_one_loss(y_test_np, y_predictions_np))\n",
        "\n",
        "#metrics for each fold\n",
        "    print(f'Score for fold {fold_num}: Loss of {zero_one_loss(y_test_np, y_predictions_np)}; Accuracy of {accuracy_score(y_test_np, y_predictions_np)}')\n",
        "\n",
        "    fold_num = fold_num + 1\n",
        "\n",
        "#average metrics\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(model_loss)):\n",
        "    print(f'> Fold {i + 1} - Loss: {model_loss[i]} - Accuracy: {model_accuracy[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(model_accuracy)} (+- {np.std(model_accuracy)})')\n",
        "print(f'> Zero-one Loss: {np.mean(model_loss)}')\n",
        "print('------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B4fVx2jat8K3"
      },
      "outputs": [],
      "source": [
        "# computing the confusion matrix for predictions at Fold 5\n",
        "confusion_mtx = confusion_matrix(y_test_np, y_predictions_np) \n",
        "f,ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#adapting arrays to use in the plot_image function\n",
        "\n",
        "y_test_np = y_test_np.astype(int)\n",
        "y_predictions_np = y_predictions_np.astype(int)\n",
        "y_test_np1 = y_test_np.flatten()\n",
        "y_pred_np1 = y_predictions_np.flatten()\n",
        "\n",
        "out_images = np.array(X_test)"
      ],
      "metadata": {
        "id": "0jXMuzr0t8K4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the first 15 test images, their predicted labels, and the true labels.\n",
        "# correct predictions are in green and incorrect predictions in red.\n",
        "\n",
        "num_rows = 5\n",
        "num_cols = 3\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, y_pred_np1[i], y_test_np1, out_images)\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "RrJtm1cVt8K5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##***Best Model: further experiments on DropBatch256***"
      ],
      "metadata": {
        "id": "WWmG2EsvCpeM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A last batch of training experiments is conducted on the best performing models changing one of the hyperparameters. Specifically:\n",
        "\n",
        "1.   The first training experiment uses Leaky Relu as activation function\n",
        "2.   The second training experiment uses Rmsprop with initial learning rate se to 0.002\n",
        "3.   The third sets the bacth size to 32\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "lY9bZsmwEQb-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "leakyr = tf.keras.layers.LeakyReLU(alpha=0.01) #hyperparameters\n",
        "RMSProp2 = RMSprop(learning_rate=0.002)"
      ],
      "metadata": {
        "id": "-R8RBVuAE0qB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_accuracy = [] #LEAKYRELU\n",
        "model_loss = []\n",
        "\n",
        "\n",
        "splits = 5\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "\n",
        "fold_num = 1\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
        "\n",
        "    dropbatch256 = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation= leakyr),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation= leakyr),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation= leakyr),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation= leakyr),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation=leakyr),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation=leakyr),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation=leakyr),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation=leakyr),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation=leakyr),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation=leakyr),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation=leakyr),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation=leakyr),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, use_bias=False, activation=leakyr),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "    dropbatch256.compile(optimizer = RMSProp, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_num} ...')\n",
        "\n",
        "    history = dropbatch256.fit(X_train, y_train, epochs = 50, batch_size = 64, verbose = 0)\n",
        "\n",
        "    #predicting and rounding to 0 and 1, computing the zero-one loss\n",
        "\n",
        "    y_predictions = dropbatch256.predict(X_test)\n",
        "    y_predictions_np = tf.round(y_predictions).numpy()\n",
        "    y_test_np = y_test.numpy() #true test labels\n",
        "\n",
        "    model_accuracy.append(accuracy_score(y_test_np, y_predictions_np))\n",
        "    model_loss.append(zero_one_loss(y_test_np, y_predictions_np))\n",
        "\n",
        "#metrics for each fold\n",
        "    print(f'Score for fold {fold_num}: Loss of {zero_one_loss(y_test_np, y_predictions_np)}; Accuracy of {accuracy_score(y_test_np, y_predictions_np)}')\n",
        "\n",
        "    fold_num = fold_num + 1\n",
        "\n",
        "#average metrics\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(model_loss)):\n",
        "    print(f'> Fold {i + 1} - Loss: {model_loss[i]} - Accuracy: {model_accuracy[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(model_accuracy)} (+- {np.std(model_accuracy)})')\n",
        "print(f'> Zero-one Loss: {np.mean(model_loss)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "ZHPBWfvgPJyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computing the confusion matrix for predictions at fold 5\n",
        "confusion_mtx = confusion_matrix(y_test_np, y_predictions_np) \n",
        "f,ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EBZmNd9rY48E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_accuracy = [] #rmsprop, different starting learning rate\n",
        "model_loss = []\n",
        "\n",
        "\n",
        "splits = 5\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "\n",
        "fold_num = 1\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
        "\n",
        "    dropbatch256 = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "    dropbatch256.compile(optimizer = RMSProp2, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_num} ...')\n",
        "\n",
        "    history = dropbatch256.fit(X_train, y_train, epochs = 50, batch_size = 64, verbose = 0)\n",
        "\n",
        "    #predicting and rounding to 0 and 1, computing the zero-one loss\n",
        "\n",
        "    y_predictions = dropbatch256.predict(X_test)\n",
        "    y_predictions_np = tf.round(y_predictions).numpy()\n",
        "    y_test_np = y_test.numpy() #true test labels\n",
        "\n",
        "    model_accuracy.append(accuracy_score(y_test_np, y_predictions_np))\n",
        "    model_loss.append(zero_one_loss(y_test_np, y_predictions_np))\n",
        "\n",
        "#metrics for each fold\n",
        "    print(f'Score for fold {fold_num}: Loss of {zero_one_loss(y_test_np, y_predictions_np)}; Accuracy of {accuracy_score(y_test_np, y_predictions_np)}')\n",
        "\n",
        "    fold_num = fold_num + 1\n",
        "\n",
        "#average metrics\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(model_loss)):\n",
        "    print(f'> Fold {i + 1} - Loss: {model_loss[i]} - Accuracy: {model_accuracy[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(model_accuracy)} (+- {np.std(model_accuracy)})')\n",
        "print(f'> Zero-one Loss: {np.mean(model_loss)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "X-m9AdfLPKuo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computing the confusion matrix for predictions at Fold 5\n",
        "confusion_mtx = confusion_matrix(y_test_np, y_predictions_np) \n",
        "f,ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aJMzMhnhZAzR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_accuracy = []  #batch size 32\n",
        "model_loss = []\n",
        "\n",
        "\n",
        "splits = 5\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
        "\n",
        "\n",
        "fold_num = 1\n",
        "for train, test in kfold.split(X, Y):\n",
        "\n",
        "    X_train, X_test, y_train, y_test = X[train], X[test], Y[train], Y[test]\n",
        "\n",
        "    dropbatch256 = tf.keras.Sequential([\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.3),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "        tf.keras.layers.BatchNormalization(),\n",
        "        tf.keras.layers.Dropout(0.4),\n",
        "        tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "    ])\n",
        "\n",
        "\n",
        "    dropbatch256.compile(optimizer = RMSProp, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_num} ...')\n",
        "\n",
        "    history = dropbatch256.fit(X_train, y_train, epochs = 50, batch_size = 32, verbose = 0)\n",
        "\n",
        "    #predicting and rounding to 0 and 1, computing the zero-one loss\n",
        "\n",
        "    y_predictions = dropbatch256.predict(X_test)\n",
        "    y_predictions_np = tf.round(y_predictions).numpy()\n",
        "    y_test_np = y_test.numpy() #true test labels\n",
        "\n",
        "    model_accuracy.append(accuracy_score(y_test_np, y_predictions_np))\n",
        "    model_loss.append(zero_one_loss(y_test_np, y_predictions_np))\n",
        "\n",
        "#metrics for each fold\n",
        "    print(f'Score for fold {fold_num}: Loss of {zero_one_loss(y_test_np, y_predictions_np)}; Accuracy of {accuracy_score(y_test_np, y_predictions_np)}')\n",
        "\n",
        "    fold_num = fold_num + 1\n",
        "\n",
        "#average metrics\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(model_loss)):\n",
        "    print(f'> Fold {i + 1} - Loss: {model_loss[i]} - Accuracy: {model_accuracy[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(model_accuracy)} (+- {np.std(model_accuracy)})')\n",
        "print(f'> Zero-one Loss: {np.mean(model_loss)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "metadata": {
        "id": "bolGUp6aPLqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computing the confusion matrix for predictions at Fold 5\n",
        "confusion_mtx = confusion_matrix(y_test_np, y_predictions_np) \n",
        "f,ax = plt.subplots(figsize=(8, 8))\n",
        "sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap=\"Greens\",linecolor=\"gray\", fmt= '.1f',ax=ax)\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cBh-X9wxZCTp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "collapsed_sections": [
        "7mA0HlJweW-Y",
        "1vUAWxKAsx_T",
        "DV5YCPrzs5Tp",
        "gvz5ARjctEML",
        "WWmG2EsvCpeM"
      ],
      "authorship_tag": "ABX9TyOfug7tQj0TMHcwdl5HmtSx",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}