{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MartaCampagnoli/MLCatsandDogs/blob/main/NoOutput/PreCrossValidationTraining_NoOutput.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3uvUJAZPg2q"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from os import listdir\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "import random\n",
        "import pathlib\n",
        "from skimage.io import imread\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras import models, layers, callbacks, regularizers\n",
        "from keras.models import Model, Sequential, load_model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.utils import to_categorical, load_img, img_to_array\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.optimizers import  SGD, RMSprop, Adam\n",
        "from keras.losses import binary_crossentropy\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
        "from sklearn.metrics import accuracy_score, zero_one_loss, confusion_matrix\n",
        "\n",
        "!pip install visualkeras\n",
        "import visualkeras\n",
        "!pip install wget\n",
        "import wget \n",
        "import zipfile\n",
        "\n",
        "\n",
        "%load_ext tensorboard\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXnDmXR7RDr2"
      },
      "outputs": [],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.isfile(\"cats_vs_dogs.zip\"): #importing the dataset\n",
        "    print(\"downloading...\")\n",
        "    wget.download(\"https://unimibox.unimi.it/index.php/s/eNGYGSYmqynNMqF/download\")\n"
      ],
      "metadata": {
        "id": "QIeOUCqxaq7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not (os.path.isdir(\"data\") and os.path.isdir(\"data/Cats\") and os.path.isdir(\"data/Dogs\")): #unzipping\n",
        "    print(\"extracting...\")\n",
        "    with zipfile.ZipFile(\"CatsDogs.zip\", 'r') as file: file.extractall(\"./data/\")"
      ],
      "metadata": {
        "id": "NdVgViLMbhte"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xoYf0qrSXwGP"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/data/CatsDogs\" \n",
        "cats_dir = data_dir + '/Cats'\n",
        "dogs_dir = data_dir + '/Dogs'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zQKRCEGSqhhQ"
      },
      "outputs": [],
      "source": [
        "size = (100, 100)\n",
        "channels = 1\n",
        "catsdogs = []\n",
        "categories = ['Cats','Dogs']\n",
        "\n",
        "def get_data():\n",
        "\n",
        "    for category in categories:\n",
        "        path = os.path.join(data_dir, category)\n",
        "\n",
        "        animalclass = categories.index(category)\n",
        "\n",
        "        for img in os.listdir(path):\n",
        "            try:\n",
        "                img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_GRAYSCALE)\n",
        "                new_array = cv2.resize(img_array, size)\n",
        "                catsdogs.append([new_array, animalclass])\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "get_data()\n",
        "\n",
        "print(len(catsdogs))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fi6N7zGMrglw"
      },
      "outputs": [],
      "source": [
        "random.shuffle(catsdogs)\n",
        "#for sample in catsdogs[:4]:\n",
        "    #print(sample[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1THknCtjFbQo"
      },
      "outputs": [],
      "source": [
        "X = []  #creating images and labels list, converting to tensor, splitting the dataset \n",
        "y = []\n",
        "\n",
        "for image, label in catsdogs:\n",
        "    X.append(image)\n",
        "    y.append(label)\n",
        "\n",
        "X = np.array(X).reshape(-1, 100, 100, channels)\n",
        "\n",
        "size = X.shape[0]\n",
        "X = tf.convert_to_tensor(X, dtype= tf.float32) / 255.0\n",
        "Y = tf.reshape(tf.convert_to_tensor(y, dtype=tf.float32), shape = [size, 1])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#earlystopping functions, loss, optimizers\n",
        "\n",
        "#earlystopping = callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                        #mode=\"min\", patience=5,\n",
        "                                        #restore_best_weights=True)\n",
        "\n",
        "earlystopping2 = callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                        mode=\"min\", patience=10,\n",
        "                                        restore_best_weights=True)\n",
        "\n",
        "earlystopping3 = callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                        mode=\"min\", patience=15,\n",
        "                                        restore_best_weights=True)\n",
        "                                         \n",
        "loss = keras.losses.BinaryCrossentropy()\n",
        "\n",
        "\n",
        "SGDM = SGD(learning_rate=0.01, momentum=0.9, decay=0.01/50)\n",
        "RMSProp = RMSprop(learning_rate=0.001)\n",
        "ADAM = Adam()"
      ],
      "metadata": {
        "id": "FY0aSG4FzfXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dorg0U0hp_TX"
      },
      "outputs": [],
      "source": [
        "#Training plots\n",
        "legend_size = 14\n",
        "\n",
        "def performance_plot(history):\n",
        "    plt.figure(figsize=(20,8))\n",
        "\n",
        "    #Loss\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.ylabel('loss', size = 12)\n",
        "    plt.xlabel('epoch', size = 12)\n",
        "    plt.legend(['train','val'], fontsize = legend_size)\n",
        "    plt.grid()\n",
        "\n",
        "    #Accuracy\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(history.history['binary_accuracy'])\n",
        "    plt.plot(history.history['val_binary_accuracy'])\n",
        "    plt.ylabel('accuracy', size = 12)\n",
        "    plt.xlabel('epoch', size = 12)\n",
        "    plt.legend(['train','val'], fontsize = legend_size)\n",
        "    plt.grid()\n",
        "\n",
        "    plt.show()\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Training the models without 5-fold cross-validation***"
      ],
      "metadata": {
        "id": "StLqNOZZsGLT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "*   ***Stack128: base model, convolutional layers with 32, 64, 128 kernels, 3 optimizers***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wKHyrbIWma9V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50 #SGDM\n",
        "\n",
        "\n",
        "stack128 = tf.keras.Sequential([\n",
        "          tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "          tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "          tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'), \n",
        "          tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "      ])\n",
        "\n",
        "stack128.compile(optimizer = SGDM, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = stack128.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test), callbacks=[earlystopping2])\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = stack128.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "WzRC4f0hmlEy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50 #RMSPROP\n",
        "\n",
        "stack128 = tf.keras.Sequential([\n",
        "          tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "          tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "          tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'), \n",
        "          tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "      ])\n",
        "\n",
        "stack128.compile(optimizer = RMSProp, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = stack128.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test), callbacks=[earlystopping2])\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = stack128.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "j-ib3r_EFIOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50 #ADAM\n",
        "\n",
        "stack128 = tf.keras.Sequential([\n",
        "          tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "          tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "          tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'), \n",
        "          tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "          tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "      ])\n",
        "\n",
        "stack128.compile(optimizer = ADAM, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = stack128.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test), callbacks=[earlystopping2])\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = stack128.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "JSJ-Sx6TFPaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   ***Stack256: base model, convolutional layers with 32, 64, 128, 256 kernels, 2 optimizers***\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KpIebaEFmoML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50 #RMSPROP\n",
        "\n",
        "stack256 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "stack256.compile(optimizer =  RMSProp, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = stack256.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test), callbacks=[earlystopping2])\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = stack256.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "DwBQoANFMABH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50 #ADAM\n",
        "\n",
        "stack256 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "stack256.compile(optimizer =  ADAM, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = stack256.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test), callbacks=[earlystopping2])\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = stack256.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "9NYnLm9qPXNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   ***Stack512: base model, convolutional layers with 32, 64, 128, 256 kernels, 2 optimizers*** \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nYNULNYjMy84"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50 #RMSPROP\n",
        "\n",
        "stack512 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'), \n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "stack512.compile(optimizer =  RMSProp, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = stack512.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test), callbacks=[earlystopping3])\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = stack512.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "8VeQrNyaY-pc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "epoch = 50 #ADAM\n",
        "\n",
        "stack512 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'), \n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "stack512.compile(optimizer = ADAM, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = stack512.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test), callbacks=[earlystopping3])\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = stack512.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "xU5oSdh7fzwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   ***Drop256: model using dropout layers and convolutional layers with 32, 64, 128, 256 kernels, 2 Optimizers***\n",
        "\n"
      ],
      "metadata": {
        "id": "FSZTEk_EYaM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50 #RMSPROP\n",
        "\n",
        "drop256 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "drop256.compile(optimizer = RMSProp, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = drop256.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test), callbacks=[earlystopping3])\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = drop256.evaluate(X_test, y_test)\n",
        "print(\"test loss, test acc:\", result)"
      ],
      "metadata": {
        "id": "RYr_kGT751_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50 #ADAM\n",
        "\n",
        "drop256 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "drop256.compile(optimizer = ADAM, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = drop256.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test), callbacks=[earlystopping3])\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = drop256.evaluate(X_test, y_test)\n",
        "print(\"test loss, test acc:\", result)"
      ],
      "metadata": {
        "id": "ZyJEwAqffiav"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   ***Drop512: model using dropout layers and convolutional layers with 32, 64, 128, 256, 512 kernels, 2 Optimizers***\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2CKcFj4OfdWC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50 #RMSPROP\n",
        "\n",
        "drop512 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "drop512.compile(optimizer = RMSProp, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = drop512.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test), callbacks=[earlystopping3])\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = drop512.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "fK5XH_3pc-AW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50 #ADAM\n",
        "\n",
        "drop512 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "drop512.compile(optimizer = ADAM, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = drop512.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test), callbacks=[earlystopping3])\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = drop512.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "n2FZMjtmsmS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*    ***DropBatch256: model using dropout and batch normalization layers and convolutional layers with 32, 64, 128, 256 kernels, 2 Optimizers***\n",
        "\n"
      ],
      "metadata": {
        "id": "Hq-Oiq6LckI3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50  #RMSPROP\n",
        "\n",
        "dropbatch256 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "dropbatch256.compile(optimizer = RMSProp, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = dropbatch256.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test))\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = dropbatch256 .evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "JP1i3srdgV22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50  #ADAM\n",
        "\n",
        "dropbatch256 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.4),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "dropbatch256 .compile(optimizer = ADAM, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = dropbatch256.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test))\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = dropbatch256.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "eWPeALn_6aRw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   ***DropBatch512: model using dropout and batch normalization layers and convolutional layers with 32, 64, 128, 256,512 kernels, 2 Optimizers***\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z_2VoG0w6d8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50  #RMSPROP\n",
        "\n",
        "\n",
        "dropbatch512 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.15),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.15),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "dropbatch512.compile(optimizer = RMSProp, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = dropbatch512.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test))\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = dropbatch512.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "i6fj2jDh6rja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50  #ADAM\n",
        "\n",
        "\n",
        "dropbatch512 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.15),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.15),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "dropbatch512.compile(optimizer = ADAM, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = dropbatch512.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test))\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = dropbatch512.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "3Y4VGVWxmarG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*  ***DropBatch1024: model using dropout and batch normalization layers and convolutional layers with 32, 64, 128, 256,512, 1024 kernels, 2 Optimizers***\n"
      ],
      "metadata": {
        "id": "9ozk0c0P6tqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50 #RMSPROP\n",
        "\n",
        "\n",
        "dropbatch1024 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(1024, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(1024, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(1024, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "dropbatch1024.compile(optimizer = RMSProp, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = dropbatch1024.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test))\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = dropbatch1024.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "HXgZDEol7L5i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50 #ADAM\n",
        "\n",
        "\n",
        "dropbatch1024 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(1024, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(1024, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(1024, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Dropout(0.3),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "dropbatch1024.compile(optimizer = ADAM, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = dropbatch1024.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test))\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = dropbatch1024.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "IOAex27hpRWe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   ***DropBatchMod1024: model using dropout and batch normalization layers and convolutional layers with 32, 64, 128, 256, 512, 1024 kernels, 2 Optimizers, Modified structure***\n",
        "\n"
      ],
      "metadata": {
        "id": "kIKa4FKhyJFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50 #RMSPROP\n",
        "\n",
        "\n",
        "dropbatchmod1024 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(1024, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(1024, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(1024, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "dropbatchmod1024.compile(optimizer = ADAM, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = dropbatchmod1024.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test))\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = dropbatchmod1024.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "zQ689pxHyJFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 50 #ADAM\n",
        "\n",
        "\n",
        "dropbatchmod1024 = tf.keras.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, input_shape = (100, 100, 1), activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(256, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(512, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Conv2D(1024, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(1024, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.Conv2D(1024, (3, 3), padding = \"same\", use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.BatchNormalization(),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size = (2, 2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(512, use_bias=False, activation='relu'),\n",
        "    tf.keras.layers.Dense(1, activation = 'sigmoid')\n",
        "])\n",
        "\n",
        "\n",
        "dropbatchmod1024.compile(optimizer = RMSProp, loss=loss, metrics=['binary_accuracy'])\n",
        "\n",
        "history = dropbatchmod1024.fit(X_train, y_train, epochs = epoch, batch_size = 64, verbose = 1, validation_data = (X_test, y_test))\n",
        "\n",
        "performance_plot(history)\n",
        "\n",
        "result = dropbatchmod1024.evaluate(X_test, y_test)\n",
        "print(f\"Test loss and accuracy:\", result)"
      ],
      "metadata": {
        "id": "IdrvikRy2yvQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyMclTiQo0ri3dwasGlpTO45",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}